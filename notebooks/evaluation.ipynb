{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### References\n",
        "- **Fuzzy F1 technique:** Lo, Andy & Jiang, Albert & Li, Wenda & Jamnik, Mateja. (2024). End-to-End Ontology Learning with Large Language Models. 10.48550/arXiv.2410.23584.\n",
        "- **WordNet treshold:** George A Miller. Wordnet: a lexical database for english. Communications of the ACM, 38(11): 39–41, 1995.\n",
        "- **Mini-Bert Model for embeddings:** Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert- networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 11 2019. URL http://arxiv.org/ abs/1908.10084.\n"
      ],
      "metadata": {
        "id": "QS5Q6z5xdLD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **What is Fuzzy F1?**\n",
        "\n",
        "The **Fuzzy F1 metric** is an evaluation metric designed to compare structured data, such as taxonomies or graphs, by considering **semantic similarity** rather than exact matches. This is particularly useful when comparing ontologies, where nodes or relationships may differ in wording but share similar meanings.\n",
        "\n",
        "Traditional metrics like Literal Precision, Recall, and F1 are overly strict because they require exact matches between nodes or relationships. For example, \"AML\" (Acute Myeloid Leukemia) and \"Acute Myeloid Leukemia\" would not be considered a match in literal comparison, even though they represent the same concept. The **Fuzzy F1 metric** addresses this limitation by using semantic similarity instead of strict equality.\n",
        "\n",
        "---\n",
        "\n",
        "## **How Does Fuzzy F1 Work?**\n",
        "\n",
        "The Fuzzy F1 metric evaluates the similarity of two graphs (e.g., a reference taxonomy and a generated taxonomy) based on **nodes** (concepts) and **edges** (relationships). It uses embeddings to compute the semantic similarity between nodes and applies a threshold to determine matches. The metric then computes **precision**, **recall**, and **F1** based on these matches.\n",
        "\n",
        "---\n",
        "\n",
        "## **Steps in Fuzzy F1 Calculation**\n",
        "\n",
        "### **1. Node Similarity Using Embeddings**\n",
        "- Each node (e.g., \"AML\" or \"Leukemia\") is converted into a vector representation using a pretrained language model, such as `all-MiniLM-L6-v2` from the SentenceTransformers library.\n",
        "- The similarity between two nodes is measured using **cosine similarity** of their embeddings:\n",
        "  $$ \\text{NodeSim}(u, u') = \\frac{\\vec{u} \\cdot \\vec{u'}}{\\|\\vec{u}\\| \\cdot \\|\\vec{u'}\\|}\n",
        "  $$\n",
        "  where $\\vec{u}$ represents the embedding of node $u$, and the similarity ranges between -1 (completely dissimilar) and 1 (identical).\n",
        "\n",
        "### **2. Edge Matching**\n",
        "- An edge $(u, v)$ in one graph is considered a match to $(u', v')$ in the other graph if:\n",
        "  $$ \\text{NodeSim}(u, u') > t \\quad \\text{and} \\quad \\text{NodeSim}(v, v') > t $$\n",
        "  where $t$ is the cosine similarity threshold, typically set to $t = 0.436$ (derived from WordNet synonyms).\n",
        "\n",
        "### **3. Fuzzy Precision**\n",
        "- Measures how many edges in the **generated graph** $E'$ are correctly matched to edges in the **reference graph** $E$:\n",
        "$$\n",
        "\\text{Fuzzy Precision} = \\frac{\\displaystyle |\\{(u', v') \\in E' \\mid \\exists (u, v) \\in E, \\text{NodeSim}(u, u') > t \\wedge \\text{NodeSim}(v, v') > t\\}|}{\\displaystyle |E'|}\n",
        "$$\n",
        "\n",
        "\n",
        "### **4. Fuzzy Recall**\n",
        "- Measures how many edges in the **reference graph** $E$ are correctly matched to edges in the **generated graph** $E'$:\n",
        "  $$\n",
        "  \\text{Fuzzy Recall} = \\frac{|\\{(u, v) \\in E \\mid \\exists (u', v') \\in E', \\text{NodeSim}(u, u') > t \\wedge \\text{NodeSim}(v, v') > t\\}|}{|E|}\n",
        "  $$\n",
        "\n",
        "### **5. Fuzzy F1 Score**\n",
        "- Combines fuzzy precision and recall into a single score:\n",
        "  $$\n",
        "  \\text{Fuzzy F1} = \\frac{2 \\cdot \\text{Fuzzy Precision} \\cdot \\text{Fuzzy Recall}}{\\text{Fuzzy Precision} + \\text{Fuzzy Recall}}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "## **Key Characteristics**\n",
        "\n",
        "- **Semantic Focus:** Unlike strict metrics, Fuzzy F1 tolerates variations in node labels by comparing their meanings using embeddings.\n",
        "- **Threshold $t$:** Determines the minimum semantic similarity for a match. For example, a lower $t$ tolerates more dissimilar matches, but risks false positives.\n",
        "- **Edge-Based Evaluation:** The metric evaluates edges (relationships) rather than just individual nodes, ensuring structural fidelity in the comparison.\n",
        "\n",
        "---\n",
        "\n",
        "## **Example**\n",
        "\n",
        "### **Input Graphs**\n",
        "\n",
        "- **Reference Graph $E$:**\n",
        "  - **Nodes:** {“Leukemia”, “Blood Cancer”}\n",
        "  - **Edge:** \\( (“Leukemia”, “Blood Cancer”) \\)\n",
        "\n",
        "- **Generated Graph $E'$:**\n",
        "  - **Nodes:** {“AML”, “Blood Cancer”}\n",
        "  - **Edge:** \\( (“AML”, “Blood Cancer”) \\)\n",
        "\n",
        "### **Embedding Similarities**\n",
        "\n",
        "- NodeSim(\"Leukemia\", \"AML\") = 0.85\n",
        "- NodeSim(\"Blood Cancer\", \"Blood Cancer\") = 1.0\n",
        "\n",
        "### **Matching**\n",
        "\n",
        "- Edge (“AML”, “Blood Cancer”) matches (“Leukemia”, “Blood Cancer”) because both node similarities exceed \\( t = 0.436 \\).\n",
        "\n",
        "### **Metric Calculation**\n",
        "\n",
        "- **Fuzzy Precision:** $\\frac{1}{1} = 1.0$\n",
        "- **Fuzzy Recall:** $\\frac{1}{1} = 1.0$\n",
        "- **Fuzzy F1:** $\\frac{2 \\cdot (1.0 \\cdot 1.0)}{1.0 + 1.0} = 1.0$\n",
        "\n"
      ],
      "metadata": {
        "id": "iK6vOGmkYmFN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGqTjKsiI_14",
        "outputId": "8fd34051-60ed-43cc-d449-7ab3424da451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/thesis')"
      ],
      "metadata": {
        "id": "Rd6FGU2oJKlX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdflib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veSE8D5HJSrK",
        "outputId": "56850c78-0374-46ba-a1f4-64a3624a6f93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdflib\n",
            "  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting isodate<1.0.0,>=0.7.2 (from rdflib)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.2.0)\n",
            "Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.7.2 rdflib-7.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wMuCIiLnOaSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdflib import Graph\n",
        "\n",
        "def extract_triples(file_path):\n",
        "    \"\"\"\n",
        "    Extracts triples (edges) from an RDF or OWL file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the RDF or OWL file.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of triples in the form (subject, predicate, object).\n",
        "    \"\"\"\n",
        "    graph = Graph()\n",
        "    graph.parse(file_path, format='xml')  # Parse RDF/OWL\n",
        "    triples = []\n",
        "    for s, p, o in graph:\n",
        "        triples.append((str(s), str(p), str(o)))  # Convert nodes to strings\n",
        "    return triples\n"
      ],
      "metadata": {
        "id": "1f73iWBwJRXQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmgJ7KHwJfK3",
        "outputId": "30fadaa7-4552-4d9e-b91b-e446958c5cbd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the sentence transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def compute_embeddings(nodes, batch_size=32):\n",
        "    \"\"\"\n",
        "    Computes embeddings for a list of nodes using a sentence transformer, with progress tracking.\n",
        "\n",
        "    Args:\n",
        "        nodes (list): List of node strings.\n",
        "        batch_size (int): Number of nodes to process in each batch.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping nodes to their embeddings.\n",
        "    \"\"\"\n",
        "    embeddings = {}\n",
        "    for i in tqdm(range(0, len(nodes), batch_size), desc=\"Computing embeddings\"):\n",
        "        batch_nodes = nodes[i:i + batch_size]  # Get the current batch\n",
        "        batch_embeddings = model.encode(batch_nodes, convert_to_numpy=True)  # Compute embeddings for the batch\n",
        "        embeddings.update(dict(zip(batch_nodes, batch_embeddings)))  # Update the dictionary with the batch results\n",
        "    return embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "SvULpcrRJg5m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"\n",
        "    Computes cosine similarity between two vectors.\n",
        "\n",
        "    Args:\n",
        "        vec1 (np.array): First embedding vector.\n",
        "        vec2 (np.array): Second embedding vector.\n",
        "\n",
        "    Returns:\n",
        "        float: Cosine similarity.\n",
        "    \"\"\"\n",
        "    return 1 - cosine(vec1, vec2)\n",
        "\n",
        "def compute_fuzzy_metrics(triples_ref, triples_gen, embeddings, threshold=0.436):\n",
        "    \"\"\"\n",
        "    Computes fuzzy precision, recall, and F1 score.\n",
        "\n",
        "    Args:\n",
        "        triples_ref (list): List of reference triples (edges).\n",
        "        triples_gen (list): List of generated triples (edges).\n",
        "        embeddings (dict): Embeddings for nodes.\n",
        "        threshold (float): Cosine similarity threshold.\n",
        "\n",
        "    Returns:\n",
        "        dict: Fuzzy precision, recall, and F1 score.\n",
        "    \"\"\"\n",
        "    fuzzy_precision_matches = 0\n",
        "    for u_prime, _, v_prime in triples_gen:\n",
        "        if u_prime not in embeddings or v_prime not in embeddings:\n",
        "            continue\n",
        "        for u, _, v in triples_ref:\n",
        "            if u not in embeddings or v not in embeddings:\n",
        "                continue\n",
        "            if (cosine_similarity(embeddings[u], embeddings[u_prime]) > threshold and\n",
        "                cosine_similarity(embeddings[v], embeddings[v_prime]) > threshold):\n",
        "                fuzzy_precision_matches += 1\n",
        "                break\n",
        "\n",
        "    fuzzy_recall_matches = 0\n",
        "    for u, _, v in triples_ref:\n",
        "        if u not in embeddings or v not in embeddings:\n",
        "            continue\n",
        "        for u_prime, _, v_prime in triples_gen:\n",
        "            if u_prime not in embeddings or v_prime not in embeddings:\n",
        "                continue\n",
        "            if (cosine_similarity(embeddings[u], embeddings[u_prime]) > threshold and\n",
        "                cosine_similarity(embeddings[v], embeddings[v_prime]) > threshold):\n",
        "                fuzzy_recall_matches += 1\n",
        "                break\n",
        "\n",
        "    fuzzy_precision = fuzzy_precision_matches / len(triples_gen) if triples_gen else 0\n",
        "    fuzzy_recall = fuzzy_recall_matches / len(triples_ref) if triples_ref else 0\n",
        "    fuzzy_f1 = (2 * fuzzy_precision * fuzzy_recall) / (fuzzy_precision + fuzzy_recall) if (fuzzy_precision + fuzzy_recall) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"Fuzzy Precision\": fuzzy_precision,\n",
        "        \"Fuzzy Recall\": fuzzy_recall,\n",
        "        \"Fuzzy F1\": fuzzy_f1\n",
        "    }\n"
      ],
      "metadata": {
        "id": "qaBs0PXDJqoC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File paths\n",
        "generated_rdf = \"/content/drive/MyDrive/thesis/results/symbolic_taxonomy.rdf\"\n",
        "reference_owl = \"/content/drive/MyDrive/thesis/benchmark/tumor_types.owl\"\n",
        "\n",
        "# Step 1: Extract triples\n",
        "triples_generated = extract_triples(generated_rdf)\n",
        "triples_reference = extract_triples(reference_owl)\n",
        "\n",
        "# Step 2: Compute embeddings\n",
        "nodes = set([node for triple in (triples_generated + triples_reference) for node in triple])\n",
        "node_embeddings = compute_embeddings(list(nodes))\n",
        "\n",
        "# Step 3: Compute fuzzy metrics\n",
        "fuzzy_metrics = compute_fuzzy_metrics(triples_reference, triples_generated, node_embeddings)\n",
        "\n",
        "# Step 4: Display results\n",
        "print(\"Fuzzy Metrics:\")\n",
        "for metric, value in fuzzy_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO0d-JnIJtdu",
        "outputId": "92d6137b-76c6-47c5-e2ec-336f1c2f0c08"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing embeddings: 100%|██████████| 5753/5753 [1:51:59<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fuzzy Metrics:\n",
            "Fuzzy Precision: 0.0898\n",
            "Fuzzy Recall: 0.0970\n",
            "Fuzzy F1: 0.0932\n"
          ]
        }
      ]
    }
  ]
}